{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# advent of code 2024 - [day 8](https://adventofcode.com/2024/day/8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_lists(file='input.txt'):\n",
    "    \"\"\"Generates tuples of integers\"\"\"\n",
    "    file = open(file, 'r')\n",
    "    for ix, line in enumerate(file):\n",
    "        for jx, c in enumerate(line.strip()):\n",
    "            yield ix, jx, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"input.txt\"\n",
    "#filename = \"test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import doctest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "NEO4J_URI = os.environ['NEO4J_URI']\n",
    "NEO4J_USERNAME = os.environ['NEO4J_USERNAME']\n",
    "NEO4J_PASSWORD = os.environ['NEO4J_PASSWORD']\n",
    "\n",
    "from graphdatascience import GraphDataScience\n",
    "gds = GraphDataScience(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "\n",
    "# Check the installed GDS version on the server\n",
    "print(gds.version())\n",
    "assert gds.version()\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def infer (rules, params={}):\n",
    "    \"\"\"\n",
    "    This is a function you can use if you want to run a set of inference rules\n",
    "    until a convergence is reached. why not use it in a RDF-like reasoning context?\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    while True:\n",
    "        counter += 1\n",
    "        any_update = False\n",
    "        for rule in rules:\n",
    "            with driver.session(database=\"neo4j\") as session:\n",
    "                result = session.run(rule, params)\n",
    "            any_update = any_update or result.consume().counters._contains_updates\n",
    "        if not any_update:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning\n",
    "def clean():\n",
    "    queries = [\n",
    "    \"CALL apoc.schema.assert({},{});\",\n",
    "    \"\"\"MATCH (n)\n",
    "    CALL {WITH n DETACH DELETE n}\n",
    "    IN TRANSACTIONS OF 1000 ROWS;\"\"\",\n",
    "    \"\"\"CALL gds.graph.list()\n",
    "    YIELD graphName\n",
    "    WITH graphName AS g\n",
    "    CALL (g) {CALL gds.graph.drop(g) YIELD graphName RETURN graphName}\n",
    "    WITH graphName RETURN graphName;\"\"\"]\n",
    "\n",
    "    for q in queries:\n",
    "        gds.run_cypher(q, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest(filename):\n",
    "\n",
    "    tiles = [{'row':ix, 'col':jx, 'val':c} for ix, jx, c in list(gen_lists(filename))]\n",
    "    \n",
    "    clean()\n",
    "\n",
    "    gds.run_cypher('CREATE INDEX tile_col_row IF NOT EXISTS FOR (t:Tile) ON (t.col, t.row)')\n",
    "    gds.run_cypher('CREATE INDEX tile_val IF NOT EXISTS FOR (t:Tile) ON (t.val)')\n",
    "    \n",
    "    query_ingest = \"\"\"\n",
    "    UNWIND $tiles AS tile\n",
    "    CREATE (:Tile {row:tile.row, col:tile.col, val:tile.val} )\n",
    "    \"\"\"\n",
    "\n",
    "    gds.run_cypher(query_ingest, {\"tiles\":tiles})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1_build_queries = [\"\"\"MATCH (t:Tile)\n",
    "SET t:InMap\"\"\",\n",
    "\"\"\"MATCH (t:Tile)\n",
    "WHERE t.val <> '.'\n",
    "SET t:Antenna\"\"\",\n",
    "\"\"\"MATCH (a1:Tile:Antenna), (a2:Tile:Antenna)\n",
    "WHERE a1.val = a2.val\n",
    "AND a1 < a2\n",
    "MERGE (a1)-[:SAME_FREQUENCY]->(a2)\"\"\",\n",
    "\"\"\"MATCH (a1:Antenna)-[:SAME_FREQUENCY]->(a2:Antenna)\n",
    "WITH a1, a2, {row: a2.row - a1.row, col: a2.col - a1.col} AS v\n",
    "MERGE (c1:Tile {row : a2.row + v.row, col : a2.col + v.col})\n",
    "  SET c1:Covered\n",
    "MERGE (c2:Tile {row : a1.row - v.row, col : a1.col - v.col})\n",
    "  SET c2:Covered\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest(filename)\n",
    "for q in part1_build_queries:\n",
    "    gds.run_cypher(q)\n",
    "gds.run_cypher('MATCH (t:InMap&Covered) RETURN count(t) AS part1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part2_build_queries = [\n",
    "\"\"\"MATCH (t:Tile)\n",
    "WHERE t.val <> '.'\n",
    "SET t:Antenna\"\"\",\n",
    "\"\"\"MATCH (a1:Tile:Antenna), (a2:Tile:Antenna)\n",
    "WHERE a1.val = a2.val\n",
    "AND a1 < a2\n",
    "SET a1:Antinode, a2:Antinode\n",
    "MERGE (a1)-[:SAME_FREQUENCY]->(a2)\"\"\",\n",
    "\"\"\"MATCH (a1:Antenna)-[:SAME_FREQUENCY]->(a2:Antenna)\n",
    "WITH a1, a2, {row: a2.row - a1.row, col: a2.col - a1.col} AS v\n",
    "MATCH (c:Tile)\n",
    "WHERE (\n",
    "  a1.col <> a2.col\n",
    "  AND c.col <> a1.col\n",
    "  AND toFloat(c.row - a1.row)/(c.col - a1.col) = toFloat(a2.row - a1.row)/(a2.col - a1.col)\n",
    ")\n",
    "OR\n",
    "c.col = a1.col = a2.col\n",
    "SET c:Antinode\"\"\",\n",
    "\"\"\"//for viz\n",
    "MATCH (t:Tile) SET t.X = t.col, t.Y = -t.row\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest(filename)\n",
    "for q in part2_build_queries:\n",
    "    gds.run_cypher(q)\n",
    "gds.run_cypher('MATCH (t:Antinode) RETURN count(t) AS part2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
