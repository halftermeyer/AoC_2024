{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# advent of code 2024 - [day 2](https://adventofcode.com/2024/day/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "NEO4J_URI = os.environ['NEO4J_URI']\n",
    "NEO4J_USERNAME = os.environ['NEO4J_USERNAME']\n",
    "NEO4J_PASSWORD = os.environ['NEO4J_PASSWORD']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphdatascience import GraphDataScience\n",
    "gds = GraphDataScience(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "\n",
    "# Check the installed GDS version on the server\n",
    "print(gds.version())\n",
    "assert gds.version()\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer (rules, params={}):\n",
    "    \"\"\"\n",
    "    This is a function you can use if you want to run a set of inference rules\n",
    "    until a convergence is reached. why not use it in a RDF-like reasoning context?\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    while True:\n",
    "        counter += 1\n",
    "        any_update = False\n",
    "        for rule in rules:\n",
    "            with driver.session(database=\"neo4j\") as session:\n",
    "                result = session.run(rule, params)\n",
    "            any_update = any_update or result.consume().counters._contains_updates\n",
    "        if not any_update:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_lists(file='input.txt'):\n",
    "    \"\"\"Generates tuples of integers\"\"\"\n",
    "    file = open(file, 'r')\n",
    "    for _, line in enumerate(file):\n",
    "        els = line.strip().split(\" \")\n",
    "        yield list(int(el) for el in els)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python-based solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_safely_increasing(l):\n",
    "    if len(l) < 2:\n",
    "        return True\n",
    "    return l[-2]+1 <= l[-1] <= l[-2]+3 and is_safely_increasing(l[:-1])\n",
    "\n",
    "\n",
    "def is_safely_decreasing(l):\n",
    "    return is_safely_increasing(list(reversed(l)))\n",
    "\n",
    "def is_safely_monotonous(l):\n",
    "    return is_safely_increasing(l) or is_safely_decreasing(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monotonous_lists = (l for l in gen_lists() if is_safely_monotonous(l) )\n",
    "part1 = len(list(monotonous_lists))\n",
    "part1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_safely_increasing(l):\n",
    "    if len(l) < 2:\n",
    "        return True\n",
    "    return l[-2]+1 <= l[-1] <= l[-2]+3 and is_safely_increasing(l[:-1])\n",
    "\n",
    "def is_safely_increasing_with_tolerance(l):\n",
    "    return any(is_safely_increasing(l[:ix]+l[ix+1:]) for ix, _ in enumerate(l))\n",
    "\n",
    "def is_safely_decreasing_with_tolerance(l):\n",
    "    return is_safely_increasing_with_tolerance(list(reversed(l)))\n",
    "\n",
    "def is_safely_monotonous_with_tolerance(l):\n",
    "    return is_safely_increasing_with_tolerance(l) or is_safely_decreasing_with_tolerance(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monotonous_lists = (l for l in gen_lists() if is_safely_monotonous_with_tolerance(l) )\n",
    "part2 = len(list(monotonous_lists))\n",
    "part2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neo4j-based solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = list(gen_lists())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ingest = \"\"\"\n",
    "UNWIND range(0, size($reports)-1) AS rep_ix\n",
    "UNWIND range(0, size($reports[rep_ix])-1) AS rec_ix\n",
    "WITH rep_ix AS report_id, rec_ix AS record_number, $reports[rep_ix][rec_ix] AS value\n",
    "CREATE (:Record {report_id: report_id, record_number: record_number, value: value})\n",
    "\"\"\"\n",
    "\n",
    "gds.run_cypher(query_ingest, {\"reports\":reports})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_chaining = \"\"\"\n",
    "MATCH (x:Record)\n",
    "WITH x ORDER BY x.record_number\n",
    "WITH x.report_id AS report_id, collect(x) AS xs\n",
    "CALL apoc.nodes.link(xs, 'NEXT');\n",
    "\"\"\"\n",
    "\n",
    "gds.run_cypher(query_chaining, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.run_cypher('CREATE INDEX record_val IF NOT EXISTS FOR (r:Record) ON (r.value)')\n",
    "gds.run_cypher('CREATE INDEX record_record_number IF NOT EXISTS FOR (r:Record) ON (r.record_number)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_part1 = \"\"\"\n",
    "CYPHER runtime=parallel\n",
    "MATCH (first:Record {record_number: 0})-[:NEXT]->(second)\n",
    "WHERE first.value <> second.value\n",
    "WITH first, second, sign(second.value-first.value) AS sign\n",
    "MATCH path = (first)(\n",
    "  (x)-[:NEXT]->(y)\n",
    "  WHERE 1 <= sign * (y.value - x.value) <= 3\n",
    ")*(last WHERE NOT EXISTS {(last)-[:NEXT]->()})\n",
    "RETURN count(path) AS part1\n",
    "\"\"\"\n",
    "\n",
    "gds.run_cypher(query_part1, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_square_chaining = \"\"\"\n",
    "MATCH (x)-[:NEXT]->{2}(y)\n",
    "MERGE (x)-[:NEXT_SQUARE]->(y)\n",
    "\"\"\"\n",
    "\n",
    "query_skip_first = \"\"\"\n",
    "MATCH (first:Record {record_number:0})-[:NEXT]->(second)\n",
    "MERGE (first)-[:SKIP_FIRST]->(second)\n",
    "\"\"\"\n",
    "\n",
    "query_skip_last = \"\"\"\n",
    "MATCH (before_last:Record)-[:NEXT]->(last)\n",
    "WHERE NOT EXISTS {(last)-[:NEXT]->()}\n",
    "MERGE (before_last)-[:SKIP_LAST]->(last)\n",
    "\"\"\"\n",
    "\n",
    "for q in [query_square_chaining, query_skip_first, query_skip_last]:\n",
    "    gds.run_cypher(q, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_part2 = \"\"\"\n",
    "CYPHER runtime=parallel\n",
    "MATCH (:Record {record_number:0})-[rsf:SKIP_FIRST]->{0,1}(first)-[rf:NEXT|NEXT_SQUARE]->(second)\n",
    "WHERE 1<= abs(second.value-first.value)<=3\n",
    "WITH first, rsf, rf, second, sign(second.value-first.value) AS sign\n",
    "MATCH path=(second)\n",
    "(\n",
    "  (x)-[rs:NEXT|NEXT_SQUARE]->(y)\n",
    "  WHERE 1 <= sign * (y.value - x.value) <= 3\n",
    ")*\n",
    "()-[rsl:SKIP_LAST]->{0,1}(last WHERE NOT EXISTS {(last)-[:NEXT]->()})\n",
    "WHERE size([r IN rsf+[rf]+rs+rsl WHERE r:NEXT_SQUARE OR r:SKIP_FIRST OR r:SKIP_LAST ]) <=1\n",
    "RETURN count(DISTINCT first.report_id) AS part2\n",
    "\"\"\"\n",
    "\n",
    "gds.run_cypher(query_part2, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
