{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# advent of code 2024 - [day 19](https://adventofcode.com/2024/day/19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "NEO4J_URI = os.environ['NEO4J_URI']\n",
    "NEO4J_USERNAME = os.environ['NEO4J_USERNAME']\n",
    "NEO4J_PASSWORD = os.environ['NEO4J_PASSWORD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "from graphdatascience import GraphDataScience\n",
    "gds = GraphDataScience(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "\n",
    "# Check the installed GDS version on the server\n",
    "print(gds.version())\n",
    "assert gds.version()\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_towels(file='input.txt'):\n",
    "    file = open(file, 'r')\n",
    "    for line in file:\n",
    "        for ix, x in enumerate(line.strip().split(',')):\n",
    "            yield {'towel_id': ix, 'towel': list(x.strip())}\n",
    "        break\n",
    "\n",
    "def parse_patterns(file='input.txt'):\n",
    "    file = open(file, 'r')\n",
    "    for ix, line in enumerate(file):\n",
    "        if ix < 2:\n",
    "            continue\n",
    "        yield {'pattern_id': ix - 2, 'pattern':tuple(line.strip())}\n",
    "\n",
    "\n",
    "def parse_patterns_fine(file='input.txt'):\n",
    "    for t in parse_patterns(file):\n",
    "        for sx, stripe in enumerate(t['pattern']):\n",
    "            yield {'pattern_id': t['pattern_id'], 'stripe_num': sx, 'color': stripe} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'input.txt'\n",
    "#filename = 'test.txt'\n",
    "\n",
    "\n",
    "patterns_elements = list(parse_patterns_fine(filename))\n",
    "towels = list(parse_towels(filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 with Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_queries = [\n",
    "\"CALL apoc.schema.assert({},{});\",\n",
    "\"\"\"MATCH (n)\n",
    "CALL {WITH n DETACH DELETE n}\n",
    "IN TRANSACTIONS OF 10000 ROWS;\"\"\",\n",
    "\"\"\"CALL gds.graph.list()\n",
    "YIELD graphName\n",
    "WITH graphName AS g\n",
    "CALL (g) {CALL gds.graph.drop(g) YIELD graphName RETURN graphName}\n",
    "WITH graphName RETURN graphName;\"\"\"]\n",
    "\n",
    "for q in clean_queries:\n",
    "    gds.run_cypher(q, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gds.run_cypher('CREATE INDEX stripe_pattern_id_stripe_num_color IF NOT EXISTS FOR (s:Stripe) ON (s.pattern_id, s.stripe_num, s.color)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_q= [\"\"\"\n",
    "UNWIND $patterns_elements AS stripe\n",
    "CREATE (s:Stripe)\n",
    "SET s += stripe\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "UNWIND $towels AS towel\n",
    "CREATE (t:Towel)\n",
    "SET t += towel\n",
    "\n",
    "\"\"\"\n",
    ",\n",
    "\"\"\"\n",
    "MATCH (s:Stripe)\n",
    "WITH s.pattern_id AS pattern, collect(s) AS stripes\n",
    "ORDER BY pattern\n",
    "CALL apoc.nodes.link(stripes,'NEXT')\n",
    "\"\"\",\n",
    "\"\"\"MATCH (s:Stripe) WHERE NOT EXISTS {()-[:NEXT]->(s)}\n",
    "SET s:First\"\"\",\n",
    "\"\"\"MATCH (s:Stripe) WHERE NOT EXISTS {(s)-[:NEXT]->()}\n",
    "SET s:Last\"\"\",\n",
    "\"\"\"\n",
    "MATCH (t:Towel)\n",
    "WITH t,\n",
    "  apoc.text.join([x IN t.towel  | \"(:Stripe {color:'\" + x + \"'})\"], '-[:NEXT]->') AS gpm_pattern\n",
    "WITH\n",
    "  t,\n",
    "  \"MATCH (t:Towel {towel_id: \"+ t.towel_id +\"})\n",
    "  MATCH path = \" + gpm_pattern + \"\n",
    "  WITH t, nodes(path)[0] AS match_first, nodes(path)[-1] AS match_last\n",
    "  CREATE (m:Match)\n",
    "  MERGE (t)-[:MATCHES]->(m)\n",
    "  MERGE (m)-[:FROM]->(match_first)\n",
    "  MERGE (m)-[:TO]->(match_last)\" AS query\n",
    "WITH t, query\n",
    "SET t.match_query = query\n",
    "\"\"\"\n",
    "]\n",
    "for q in build_q:\n",
    "    gds.run_cypher(q, {'patterns_elements':patterns_elements, 'towels': towels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_queries = gds.run_cypher(\"MATCH (t:Towel) RETURN collect(t.match_query) AS match_queries\")['match_queries'][0]\n",
    "for q in match_queries:\n",
    "    gds.run_cypher(q, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   part1\n",
       "0    340"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gds.run_cypher(\"\"\"\n",
    "MATCH (first:First)\n",
    "CALL (first) {\n",
    "MATCH path = (first)(()<-[:FROM]-()-[:TO]->()-[:NEXT]->())+()<-[:FROM]-()-[:TO]->(last:Last)\n",
    "RETURN path LIMIT 1\n",
    "} IN CONCURRENT TRANSACTIONS OF 100 ROWS\n",
    "RETURN count(DISTINCT first) AS part1\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 with dynamic programming\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_towels(file='input.txt'):\n",
    "    file = open(file, 'r')\n",
    "    for line in file:\n",
    "        for ix, x in enumerate(line.strip().split(',')):\n",
    "            yield x.strip()\n",
    "        break\n",
    "\n",
    "def parse_patterns(file='input.txt'):\n",
    "    file = open(file, 'r')\n",
    "    for ix, line in enumerate(file):\n",
    "        if ix < 2:\n",
    "            continue\n",
    "        yield line.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "717561822679428"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import cache\n",
    "\n",
    "@cache\n",
    "def num_solutions(pattern, towels):\n",
    "    acc = 0\n",
    "    for towel in towels:\n",
    "        if pattern == towel:\n",
    "            acc += 1\n",
    "        elif pattern.startswith(towel):\n",
    "            l = len(towel)\n",
    "            acc += num_solutions(pattern[l:], towels)\n",
    "        else:\n",
    "            pass\n",
    "    return acc\n",
    "\n",
    "part2 = 0\n",
    "towels = tuple(parse_towels(filename))\n",
    "\n",
    "for pattern in parse_patterns(filename):\n",
    "    part2 += num_solutions(pattern, towels)\n",
    "\n",
    "part2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
